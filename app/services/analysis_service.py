"""
èƒŒè¯µåˆ†ææœåŠ¡
åŸºäºASRå’Œå‘éŸ³è¯„ä¼°ç®—æ³•çš„æ™ºèƒ½èƒŒè¯µåˆ†æç³»ç»Ÿ
"""
import re
import time
from typing import List, Optional, Dict
from difflib import SequenceMatcher
import aiohttp
from fastapi import HTTPException

from app.core.config import settings
from app.services.media_service import MediaProcessingService
from app.schemas.analysis import (
    RecitationAnalysisRequest,
    RecitationAnalysisResponse,
    RecitationAnalysis,
    RecitationScores,
    WordScore,
    ASRResponse,
    ASRWord,
    CloudflareASRResponse,
    WordAlignment
)


class RecitationAnalysisService:
    """èƒŒè¯µåˆ†ææœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        self.session: Optional[aiohttp.ClientSession] = None
        self.media_service = MediaProcessingService()
    
    async def analyze_recitation(self, request: RecitationAnalysisRequest) -> RecitationAnalysisResponse:
        """
        åˆ†æç”¨æˆ·çš„èƒŒè¯µæƒ…å†µ
        
        Args:
            request: åˆ†æè¯·æ±‚ï¼ŒåŒ…å«åŸå§‹æ–‡æœ¬å’ŒéŸ³é¢‘URL
            
        Returns:
            RecitationAnalysisResponse: å®Œæ•´çš„åˆ†æç»“æœ
        """
        start_time = time.time()
        
        try:
            # 1. è°ƒç”¨ASRæ¥å£è·å–è½¬å½•æ–‡æœ¬
            asr_result = await self._call_asr_api(request.audio_url, request.language)
            
            # 2. é¢„å¤„ç†æ–‡æœ¬
            original_words = self._preprocess_text(request.original_text)
            recognized_words = self._preprocess_text(asr_result.text)
            
            # 3. è¿›è¡Œè¯è¯­å¯¹é½
            word_alignments = self._align_words(
                original_words, 
                recognized_words, 
                asr_result.words
            )
            
            # 4. è®¡ç®—å„ç§è¯„åˆ†
            analysis = self._calculate_analysis_scores(
                original_words, 
                recognized_words, 
                word_alignments, 
                asr_result
            )
        
            
            processing_time = time.time() - start_time
            
            return RecitationAnalysisResponse(
                success=True,
                analysis=analysis,
                processing_time=processing_time
            )
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"èƒŒè¯µåˆ†æå¤±è´¥: {str(e)}"
            )
    
    async def _call_asr_api(self, audio_url: str, language: str = "zh") -> ASRResponse:
        """
        è°ƒç”¨Cloudflareçš„Whisper ASR API
        
        Args:
            audio_url: éŸ³é¢‘æ–‡ä»¶URL
            language: è¯­è¨€ä»£ç ï¼ˆzhä¸­æ–‡ï¼Œenè‹±æ–‡ï¼‰
            
        Returns:
            ASRResponse: ASRè¯†åˆ«ç»“æœ
        """
        try:
            # æ„å»ºAPI URL
            api_url = f"{settings.asr_api_base_url}/{settings.cloudflare_account_id}/ai/run/{settings.asr_model}"
            if language:
                api_url += f"?language={language}"
            
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {settings.cloudflare_api_token}",
                "Content-Type": "application/octet-stream"
            }
            
            # åˆ›å»ºä¼šè¯ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if not self.session:
                self.session = aiohttp.ClientSession(
                    timeout=aiohttp.ClientTimeout(total=settings.analysis_timeout)
                )
            
            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
            async with self.session.get(audio_url) as audio_response:
                if audio_response.status != 200:
                    raise Exception(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶: HTTP {audio_response.status}")
                audio_data = await audio_response.read()

            # é¢„å¤„ç†éŸ³é¢‘æ•°æ®ï¼šæ£€æµ‹æ–‡ä»¶ç±»å‹ï¼Œè‹¥ä¸ºè§†é¢‘åˆ™è½¬ç ä¸ºéŸ³é¢‘ï¼Œå°†å¤šå£°é“éŸ³é¢‘è½¬æ¢ä¸ºå•å£°é“
            try:
                processed_audio_data = await self.media_service.preprocess_audio_for_asr(
                    audio_data, audio_url
                )
            except Exception as e:
                # å¦‚æœé¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®ä½œä¸ºåå¤‡æ–¹æ¡ˆ
                print(f"éŸ³é¢‘é¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {str(e)}")
                processed_audio_data = audio_data
            
            # è°ƒç”¨ASR API
            async with self.session.post(api_url, headers=headers, data=processed_audio_data) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"ASR APIè°ƒç”¨å¤±è´¥: HTTP {response.status}, {error_text}")
                
                response_data = await response.json()
                
                # è§£æå“åº”
                cf_response = CloudflareASRResponse(**response_data)
                
                if not cf_response.success:
                    error_msg = ", ".join(cf_response.errors) if cf_response.errors else "æœªçŸ¥é”™è¯¯"
                    raise Exception(f"ASRè¯†åˆ«å¤±è´¥: {error_msg}")
                
                # è½¬æ¢å•è¯æ•°æ®æ ¼å¼
                asr_words = []
                for word_data in cf_response.result.words:
                    asr_words.append(ASRWord(
                        word=word_data.word,
                        start=word_data.start,
                        end=word_data.end,
                        confidence=None
                    ))
                
                return ASRResponse(
                    text=cf_response.result.text,
                    word_count=cf_response.result.word_count,
                    words=asr_words,
                    vtt=cf_response.result.vtt
                )
                
        except Exception as e:
            raise Exception(f"ASRå¤„ç†å¤±è´¥: {str(e)}")
    
    def _preprocess_text(self, text: str) -> List[str]:
        """
        æ–‡æœ¬é¢„å¤„ç†ï¼šæ¸…ç†æ ‡ç‚¹ç¬¦å·ï¼Œåˆ†è¯
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            List[str]: å¤„ç†åçš„å•è¯åˆ—è¡¨
        """
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
        
        # è½¬æ¢ä¸ºå°å†™ï¼ˆå¯¹è‹±æ–‡ï¼‰
        text = text.lower()
        
        # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼åˆ†å‰²ï¼Œä¸­æ–‡å­—ç¬¦å•ç‹¬å¤„ç†ï¼‰
        if self._is_chinese_text(text):
            # ä¸­æ–‡æŒ‰å­—ç¬¦åˆ†å‰²
            words = [char for char in text if char.strip()]
        else:
            # è‹±æ–‡æŒ‰ç©ºæ ¼åˆ†å‰²
            words = text.split()
        
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
        return [word for word in words if word.strip()]
    
    def _is_chinese_text(self, text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸»è¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        chinese_count = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        total_chars = len([char for char in text if char.strip()])
        return chinese_count > total_chars * 0.5 if total_chars > 0 else False
    
    def _align_words(
        self, 
        expected_words: List[str], 
        actual_words: List[str], 
        asr_words: List[ASRWord]
    ) -> List[WordAlignment]:
        """
        è¯è¯­å¯¹é½ç®—æ³•ï¼ˆåŸºäºç¼–è¾‘è·ç¦»å’Œç›¸ä¼¼åº¦ï¼‰
        
        Args:
            expected_words: æœŸæœ›çš„å•è¯åˆ—è¡¨
            actual_words: å®é™…è¯†åˆ«çš„å•è¯åˆ—è¡¨
            asr_words: ASRæä¾›çš„å¸¦æ—¶é—´æˆ³çš„å•è¯ä¿¡æ¯
            
        Returns:
            List[WordAlignment]: å¯¹é½ç»“æœ
        """
        alignments = []
        
        # åˆ›å»ºæ—¶é—´æˆ³å­—å…¸
        word_timestamps: Dict[str, Dict[str, float]] = {}
        for asr_word in asr_words:
            clean_word = re.sub(r'[^\w\s\u4e00-\u9fff]', '', asr_word.word.lower())
            word_timestamps[clean_word] = {
                'start': float(asr_word.start),
                'end': float(asr_word.end)
            }
        
        # ä½¿ç”¨åŠ¨æ€è§„åˆ’è¿›è¡Œåºåˆ—å¯¹é½
        dp = [[0.0] * (len(actual_words) + 1) for _ in range(len(expected_words) + 1)]
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        for i in range(1, len(expected_words) + 1):
            for j in range(1, len(actual_words) + 1):
                similarity = self._calculate_word_similarity(
                    expected_words[i-1], 
                    actual_words[j-1]
                )
                
                # ä¸‰ç§æ“ä½œï¼šåŒ¹é…ã€åˆ é™¤ã€æ’å…¥
                match_score = dp[i-1][j-1] + similarity
                delete_score = dp[i-1][j] - 0.5
                insert_score = dp[i][j-1] - 0.5
                
                dp[i][j] = max(match_score, delete_score, insert_score)
        
        # å›æº¯æ‰¾åˆ°æœ€ä¼˜å¯¹é½è·¯å¾„
        i, j = len(expected_words), len(actual_words)
        while i > 0 and j > 0:
            expected_word = expected_words[i-1]
            actual_word = actual_words[j-1]
            similarity = self._calculate_word_similarity(expected_word, actual_word)
            
            # è·å–æ—¶é—´æˆ³
            timestamps = word_timestamps.get(actual_word, {'start': 0.0, 'end': 0.0})
            
            if abs(dp[i][j] - (dp[i-1][j-1] + similarity)) < 1e-6:
                # åŒ¹é…
                alignments.append(WordAlignment(
                    expected_word=expected_word,
                    actual_word=actual_word,
                    similarity=similarity,
                    start_time=timestamps['start'],
                    end_time=timestamps['end'],
                    is_match=similarity >= settings.min_word_similarity
                ))
                i -= 1
                j -= 1
            elif abs(dp[i][j] - (dp[i-1][j] - 0.5)) < 1e-6:
                # åˆ é™¤ï¼ˆé—æ¼ï¼‰
                alignments.append(WordAlignment(
                    expected_word=expected_word,
                    actual_word="",
                    similarity=0.0,
                    start_time=0.0,
                    end_time=0.0,
                    is_match=False
                ))
                i -= 1
            else:
                # æ’å…¥ï¼ˆå¤šä½™ï¼‰
                timestamps = word_timestamps.get(actual_word, {'start': 0.0, 'end': 0.0})
                alignments.append(WordAlignment(
                    expected_word="",
                    actual_word=actual_word,
                    similarity=0.0,
                    start_time=timestamps['start'],
                    end_time=timestamps['end'],
                    is_match=False
                ))
                j -= 1
        
        # å¤„ç†å‰©ä½™çš„è¯
        while i > 0:
            alignments.append(WordAlignment(
                expected_word=expected_words[i-1],
                actual_word="",
                similarity=0.0,
                start_time=0.0,
                end_time=0.0,
                is_match=False
            ))
            i -= 1
        
        while j > 0:
            actual_word = actual_words[j-1]
            timestamps = word_timestamps.get(actual_word, {'start': 0.0, 'end': 0.0})
            alignments.append(WordAlignment(
                expected_word="",
                actual_word=actual_word,
                similarity=0.0,
                start_time=timestamps['start'],
                end_time=timestamps['end'],
                is_match=False
            ))
            j -= 1
        
        return list(reversed(alignments))
    
    def _calculate_word_similarity(self, word1: str, word2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå•è¯çš„ç›¸ä¼¼åº¦
        
        Args:
            word1: å•è¯1
            word2: å•è¯2
            
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        """
        if word1 == word2:
            return 1.0
        
        # ä½¿ç”¨åºåˆ—åŒ¹é…å™¨è®¡ç®—ç›¸ä¼¼åº¦
        matcher = SequenceMatcher(None, word1.lower(), word2.lower())
        return matcher.ratio()
    
    def _calculate_analysis_scores(
        self, 
        expected_words: List[str], 
        recognized_words: List[str], 
        word_alignments: List[WordAlignment],
        asr_result: ASRResponse
    ) -> RecitationAnalysis:
        """
        è®¡ç®—å„ç§åˆ†æè¯„åˆ†
        
        Args:
            expected_words: æœŸæœ›å•è¯åˆ—è¡¨
            recognized_words: è¯†åˆ«å•è¯åˆ—è¡¨
            word_alignments: è¯è¯­å¯¹é½ç»“æœ
            asr_result: ASRç»“æœ
            
        Returns:
            RecitationAnalysis: å®Œæ•´åˆ†æç»“æœ
        """
        # ç»Ÿè®¡åŸºæœ¬æŒ‡æ ‡
        total_words = len(expected_words)
        correct_words = sum(1 for alignment in word_alignments if alignment.is_match)
        word_accuracy = (correct_words / total_words * 100) if total_words > 0 else 0
        
        # ç”Ÿæˆå•è¯è¯¦ç»†åˆ†æ
        word_details = []
        mispronounced_words = []
        missing_words = []
        extra_words = []
        
        for alignment in word_alignments:
            if alignment.expected_word and alignment.actual_word:
                # åŒ¹é…çš„è¯
                score = alignment.similarity * 100
                is_correct = alignment.is_match
                
                word_details.append(WordScore(
                    word=alignment.expected_word,
                    expected=alignment.expected_word,
                    actual=alignment.actual_word,
                    score=score,
                    start_time=alignment.start_time,
                    end_time=alignment.end_time,
                    is_correct=is_correct
                ))
                
                if not is_correct:
                    mispronounced_words.append(alignment.expected_word)
                    
            elif alignment.expected_word and not alignment.actual_word:
                # é—æ¼çš„è¯
                missing_words.append(alignment.expected_word)
                word_details.append(WordScore(
                    word=alignment.expected_word,
                    expected=alignment.expected_word,
                    actual="",
                    score=0.0,
                    start_time=0.0,
                    end_time=0.0,
                    is_correct=False
                ))
            elif not alignment.expected_word and alignment.actual_word:
                # å¤šä½™çš„è¯
                extra_words.append(alignment.actual_word)
        
        # è®¡ç®—å„é¡¹è¯„åˆ†
        pronunciation_score = self._calculate_pronunciation_score(word_alignments)
        fluency_score = self._calculate_fluency_score(asr_result, word_alignments)
        accuracy_score = word_accuracy / 10  # è½¬æ¢ä¸º10åˆ†åˆ¶
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        overall_score = (
            pronunciation_score * settings.pronunciation_accuracy_weight +
            fluency_score * settings.fluency_weight +
            accuracy_score * settings.accuracy_weight
        )
        
        scores = RecitationScores(
            accuracy_score=round(accuracy_score, 2),
            fluency_score=round(fluency_score, 2),
            pronunciation_score=round(pronunciation_score, 2),
            overall_score=round(overall_score, 2)
        )
        
        return RecitationAnalysis(
            recognized_text=asr_result.text,
            word_count=total_words,
            correct_words=correct_words,
            word_accuracy=round(word_accuracy, 2),
            scores=scores,
            word_details=word_details,
            phoneme_details=None,  # æš‚ä¸æ”¯æŒéŸ³ç´ çº§åˆ†æ
            mispronounced_words=mispronounced_words,
            missing_words=missing_words,
            extra_words=extra_words
        )
    
    def _calculate_pronunciation_score(self, word_alignments: List[WordAlignment]) -> float:
        """
        è®¡ç®—å‘éŸ³å‡†ç¡®åº¦è¯„åˆ†
        
        Args:
            word_alignments: è¯è¯­å¯¹é½ç»“æœ
            
        Returns:
            float: å‘éŸ³å‡†ç¡®åº¦è¯„åˆ†ï¼ˆ0-10ï¼‰
        """
        if not word_alignments:
            return 0.0
        
        # è®¡ç®—å¹³å‡ç›¸ä¼¼åº¦
        matched_alignments = [
            alignment for alignment in word_alignments 
            if alignment.expected_word and alignment.actual_word
        ]
        
        if not matched_alignments:
            return 0.0
        
        avg_similarity = sum(alignment.similarity for alignment in matched_alignments) / len(matched_alignments)
        return min(avg_similarity * 10, 10.0)
    
    def _calculate_fluency_score(self, asr_result: ASRResponse, word_alignments: List[WordAlignment]) -> float:
        """
        è®¡ç®—æµç•…åº¦è¯„åˆ†
        
        Args:
            asr_result: ASRç»“æœ
            word_alignments: è¯è¯­å¯¹é½ç»“æœ
            
        Returns:
            float: æµç•…åº¦è¯„åˆ†ï¼ˆ0-10ï¼‰
        """
        # åŸºäºè¯­é€Ÿå’Œåœé¡¿æ¥è®¡ç®—æµç•…åº¦
        if not asr_result.words:
            return 5.0  # é»˜è®¤åˆ†æ•°
        
        # è®¡ç®—æ€»æ—¶é•¿
        total_duration = asr_result.words[-1].end - asr_result.words[0].start
        
        # è®¡ç®—è¯­é€Ÿï¼ˆè¯/åˆ†é’Ÿï¼‰
        words_per_minute = (len(asr_result.words) / total_duration) * 60
        
        # ç†æƒ³è¯­é€ŸèŒƒå›´ï¼ˆæ ¹æ®è¯­è¨€è°ƒæ•´ï¼‰
        ideal_wpm_min, ideal_wpm_max = 120.0, 180.0  # ä¸­æ–‡å­—ç¬¦/åˆ†é’Ÿ
        
        # è¯­é€Ÿè¯„åˆ†
        if ideal_wpm_min <= words_per_minute <= ideal_wpm_max:
            speed_score = 10.0
        else:
            # åç¦»ç†æƒ³èŒƒå›´çš„æƒ©ç½š
            deviation = min(
                abs(words_per_minute - ideal_wpm_min),
                abs(words_per_minute - ideal_wpm_max)
            )
            speed_score = max(10.0 - (deviation / 20), 1.0)
        
        # åœé¡¿è¯„åˆ†ï¼ˆåŸºäºè¯é—´é—´éš”ï¼‰
        pause_score = self._calculate_pause_score(asr_result.words)
        
        # ç»¼åˆæµç•…åº¦è¯„åˆ†
        fluency_score = (speed_score * 0.7 + pause_score * 0.3)
        return min(fluency_score, 10.0)
    
    def _calculate_pause_score(self, words: List[ASRWord]) -> float:
        """
        è®¡ç®—åœé¡¿è¯„åˆ†
        
        Args:
            words: å¸¦æ—¶é—´æˆ³çš„å•è¯åˆ—è¡¨
            
        Returns:
            float: åœé¡¿è¯„åˆ†ï¼ˆ0-10ï¼‰
        """
        if len(words) < 2:
            return 8.0
        
        # è®¡ç®—è¯é—´é—´éš”
        intervals = []
        for i in range(1, len(words)):
            interval = words[i].start - words[i-1].end
            intervals.append(interval)
        
        # åˆ†æåœé¡¿æ¨¡å¼
        avg_interval = sum(intervals) / len(intervals)
        long_pauses = sum(1 for interval in intervals if interval > 1.0)  # è¶…è¿‡1ç§’çš„åœé¡¿
        
        # è¯„åˆ†é€»è¾‘
        if avg_interval < 0.5 and long_pauses == 0:
            return 10.0
        elif avg_interval < 1.0 and long_pauses <= 2:
            return 8.0
        elif avg_interval < 2.0 and long_pauses <= 5:
            return 6.0
        else:
            return max(4.0 - long_pauses * 0.5, 1.0)
    
    def _generate_ai_feedback(self, analysis: RecitationAnalysis) -> str:
        """
        ç”ŸæˆAIåé¦ˆå»ºè®®
        
        Args:
            analysis: åˆ†æç»“æœ
            
        Returns:
            str: äººæ€§åŒ–çš„åé¦ˆå»ºè®®
        """
        overall_score = analysis.scores.overall_score
        accuracy = analysis.word_accuracy
        
        # åŸºç¡€è¯„ä»·
        if overall_score >= 8.5:
            base_feedback = "ğŸ‰ å¤ªæ£’äº†ï¼ä½ çš„èƒŒè¯µéå¸¸å‡ºè‰²ï¼"
        elif overall_score >= 7.0:
            base_feedback = "ğŸ‘ å¾ˆå¥½ï¼ä½ çš„èƒŒè¯µè´¨é‡å¾ˆä¸é”™ï¼"
        elif overall_score >= 5.5:
            base_feedback = "ğŸ’ª ä¸é”™çš„å°è¯•ï¼è¿˜æœ‰è¿›æ­¥çš„ç©ºé—´ã€‚"
        else:
            base_feedback = "ğŸŒŸ åŠ æ²¹ï¼å¤šç»ƒä¹ ä¸€å®šä¼šæœ‰æå‡çš„ã€‚"
        
        # å…·ä½“å»ºè®®
        suggestions = []
        
        # æ­£ç¡®ç‡å»ºè®®
        if accuracy < 70:
            suggestions.append("å»ºè®®å¤šç†Ÿæ‚‰æ–‡æœ¬å†…å®¹ï¼Œç¡®ä¿å‡†ç¡®è®°å¿†æ¯ä¸ªè¯è¯­")
        elif accuracy < 85:
            suggestions.append("å¯¹ä¸ªåˆ«è¯è¯­çš„å‘éŸ³å¯ä»¥å†åŠ å¼ºç»ƒä¹ ")
        
        # å‘éŸ³å»ºè®®
        if analysis.scores.pronunciation_score < 7:
            suggestions.append("æ³¨æ„å‘éŸ³çš„æ¸…æ™°åº¦ï¼Œå¯ä»¥æ”¾æ…¢é€Ÿåº¦ç¡®ä¿æ¯ä¸ªå­—éŸ³å‡†ç¡®")
            if analysis.mispronounced_words:
                problem_words = analysis.mispronounced_words[:3]  # æœ€å¤šæåŠ3ä¸ª
                suggestions.append(f"ç‰¹åˆ«æ³¨æ„è¿™äº›è¯çš„å‘éŸ³ï¼š{', '.join(problem_words)}")
        
        # æµç•…åº¦å»ºè®®
        if analysis.scores.fluency_score < 7:
            suggestions.append("å¯ä»¥æé«˜è¯­é€Ÿï¼Œå‡å°‘ä¸å¿…è¦çš„åœé¡¿ï¼Œè®©èƒŒè¯µæ›´åŠ æµç•…")
        
        # é—æ¼å’Œå¤šä½™è¯è¯­
        if analysis.missing_words:
            suggestions.append(f"æ³¨æ„ä¸è¦é—æ¼è¿™äº›å†…å®¹ï¼š{', '.join(analysis.missing_words[:2])}")
        
        if analysis.extra_words:
            suggestions.append("å°½é‡é¿å…æ·»åŠ é¢å¤–çš„è¯è¯­ï¼Œä¸¥æ ¼æŒ‰ç…§åŸæ–‡èƒŒè¯µ")
        
        # ç»„åˆåé¦ˆ
        feedback = base_feedback
        if suggestions:
            feedback += "\n\nğŸ“ æ”¹è¿›å»ºè®®ï¼š\n" + "\n".join(f"â€¢ {suggestion}" for suggestion in suggestions[:4])
        
        # é¼“åŠ±è¯­
        feedback += f"\n\nğŸ“Š æœ¬æ¬¡å¾—åˆ†ï¼š{overall_score}/10åˆ†ï¼Œç»§ç»­åŠªåŠ›ï¼Œä½ ä¸€å®šèƒ½åšå¾—æ›´å¥½ï¼"
        
        return feedback
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
            self.session = None
        # æ³¨æ„ï¼šmedia_service ä¸éœ€è¦ç‰¹åˆ«çš„æ¸…ç†ï¼Œå› ä¸ºå®ƒä½¿ç”¨çš„æ˜¯åŒæ­¥çš„supabaseå®¢æˆ·ç«¯ 