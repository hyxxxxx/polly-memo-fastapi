#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•™æè¯¾æ–‡å¤„ç†å·¥ä½œæµ

æ­¤è„šæœ¬æ•´åˆäº†æ•™æå¤„ç†çš„å®Œæ•´æµç¨‹ï¼š
1. Wordæ–‡æ¡£æ¨¡å—åˆ†å‰²
2. è¯¾æ–‡ç»“æ„åŒ–æå–
3. èƒŒè¯µæ—¶é—´ä¼°ç®—
4. ç”Ÿæˆæœ€ç»ˆçš„SQLæ’å…¥è¯­å¥

ä½¿ç”¨ç¤ºä¾‹:
    python textbook_workflow.py --input "path/to/textbook.doc" --textbook_id 1
"""

import asyncio
import argparse
import json
import os
import sys
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from datetime import datetime
import re
from docx import Document

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

from app.services.glm4_service import GLM4Service
from app.schemas.glm4 import GLM4Request

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('textbook_workflow.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def estimate_memorization_time_simple(word_count: int, difficulty_level: int = 2) -> int:
    """
    ç®€åŒ–ç‰ˆçš„è‹±æ–‡è¯¾æ–‡èƒŒè¯µæ—¶é—´ä¼°ç®—ç®—æ³•
    
    å‚æ•°:
    word_count (int): è¯¾æ–‡çš„å•è¯æ•°é‡
    difficulty_level (int): è¯¾æ–‡éš¾åº¦çº§åˆ« (1-ç®€å•, 2-ä¸­ç­‰, 3-å›°éš¾)
    
    è¿”å›:
    int: æ¨èçš„èƒŒè¯µæ—¶é•¿ï¼ˆæ•´æ•°åˆ†é’Ÿï¼Œä¸è¶³1åˆ†é’ŸæŒ‰1åˆ†é’Ÿè®¡ï¼‰
    """
    
    # åŸºç¡€èƒŒè¯µé€Ÿåº¦ï¼ˆå•è¯/åˆ†é’Ÿï¼‰ - åŸºäºä¸­ç­‰æ°´å¹³å­¦ç”Ÿ
    base_speed = 3.0
    
    # éš¾åº¦ç³»æ•°
    difficulty_factors = {1: 0.7, 2: 1.0, 3: 1.5}
    
    # è®¡ç®—åŸºç¡€è®°å¿†æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    base_time = word_count / base_speed
    
    # åº”ç”¨éš¾åº¦ç³»æ•°
    memorization_time = base_time * difficulty_factors.get(difficulty_level, 1.0)
    
    # è€ƒè™‘ç†è§£å†…å®¹å¸¦æ¥çš„æ•ˆç‡æå‡ï¼ˆé»˜è®¤å­¦ç”Ÿç†è§£å†…å®¹ï¼‰
    comprehension_bonus = 0.7  # ç†è§£å†…å®¹å¯å‡å°‘30%çš„æ—¶é—´
    
    # æœ€ç»ˆæ¨èæ—¶é—´
    recommended_time = memorization_time * comprehension_bonus
    
    # å‘ä¸Šå–æ•´åˆ°æ•´æ•°åˆ†é’Ÿï¼Œæœ€å°‘1åˆ†é’Ÿ
    return max(1, int(recommended_time + 0.5))


def count_words(text: str) -> int:
    """
    è®¡ç®—è‹±æ–‡æ–‡æœ¬çš„å•è¯æ•°é‡
    
    Args:
        text: è‹±æ–‡æ–‡æœ¬
        
    Returns:
        int: å•è¯æ•°é‡
    """
    if not text:
        return 0
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è‹±æ–‡å•è¯
    words = re.findall(r'\b[A-Za-z]+\b', text)
    return len(words)


def convert_doc_to_docx(doc_file_path: str) -> str:
    """
    å°†.docæ–‡ä»¶è½¬æ¢ä¸º.docxæ ¼å¼
    
    Args:
        doc_file_path (str): .docæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: è½¬æ¢åçš„.docxæ–‡ä»¶è·¯å¾„
        
    Raises:
        Exception: è½¬æ¢å¤±è´¥
    """
    import subprocess
    
    docx_file_path = doc_file_path.rsplit('.', 1)[0] + '.docx'
    
    # å°è¯•ä½¿ç”¨LibreOfficeè¿›è¡Œè½¬æ¢
    try:
        logger.info("å°è¯•ä½¿ç”¨LibreOfficeè½¬æ¢.docæ–‡ä»¶...")
        result = subprocess.run([
            'libreoffice', '--headless', '--convert-to', 'docx', 
            '--outdir', os.path.dirname(doc_file_path), doc_file_path
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0 and os.path.exists(docx_file_path):
            logger.info(f"âœ“ å·²ä½¿ç”¨LibreOfficeå°†.docæ–‡ä»¶è½¬æ¢ä¸º.docxæ ¼å¼: {docx_file_path}")
            return docx_file_path
            
    except FileNotFoundError:
        pass  # LibreOfficeä¸å¯ç”¨ï¼Œç»§ç»­å°è¯•å…¶ä»–æ–¹æ³•
    except subprocess.TimeoutExpired:
        logger.warning("LibreOfficeè½¬æ¢è¶…æ—¶")
    except Exception as e:
        logger.warning(f"LibreOfficeè½¬æ¢å¤±è´¥: {str(e)}")
    
    # å°è¯•ä½¿ç”¨textutil (macOSè‡ªå¸¦å·¥å…·)
    try:
        logger.info("å°è¯•ä½¿ç”¨textutilè½¬æ¢.docæ–‡ä»¶...")
        # å…ˆè½¬æ¢ä¸ºrtfæ ¼å¼ï¼Œå†ç”¨pandocè½¬æ¢ä¸ºdocx
        rtf_file_path = doc_file_path.rsplit('.', 1)[0] + '.rtf'
        
        # .doc -> .rtf
        result1 = subprocess.run([
            'textutil', '-convert', 'rtf', doc_file_path, '-output', rtf_file_path
        ], capture_output=True, text=True)
        
        if result1.returncode == 0 and os.path.exists(rtf_file_path):
            # .rtf -> .docx
            result2 = subprocess.run([
                'pandoc', rtf_file_path, '-o', docx_file_path
            ], capture_output=True, text=True)
            
            # æ¸…ç†ä¸´æ—¶rtfæ–‡ä»¶
            if os.path.exists(rtf_file_path):
                os.remove(rtf_file_path)
                
            if result2.returncode == 0 and os.path.exists(docx_file_path):
                logger.info(f"âœ“ å·²ä½¿ç”¨textutil+pandocå°†.docæ–‡ä»¶è½¬æ¢ä¸º.docxæ ¼å¼: {docx_file_path}")
                return docx_file_path
                
    except FileNotFoundError:
        pass  # textutilä¸å¯ç”¨ï¼ˆémacOSç³»ç»Ÿï¼‰
    except Exception as e:
        logger.warning(f"textutilè½¬æ¢å¤±è´¥: {str(e)}")
    
    # æ‰€æœ‰è‡ªåŠ¨è½¬æ¢æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œç»™å‡ºè¯¦ç»†çš„æ‰‹åŠ¨è½¬æ¢æŒ‡å¯¼
    raise Exception(
        f"âŒ æ— æ³•è‡ªåŠ¨è½¬æ¢.docæ–‡ä»¶ã€‚Pandocä¸æ”¯æŒ.docæ ¼å¼ï¼ˆåªæ”¯æŒ.docxï¼‰ã€‚\n\n"
        f"è¯·é€‰æ‹©ä»¥ä¸‹è§£å†³æ–¹æ¡ˆä¹‹ä¸€ï¼š\n\n"
        f"ğŸ”§ è§£å†³æ–¹æ¡ˆ1ï¼šä½¿ç”¨Microsoft Word\n"
        f"   1. ç”¨Wordæ‰“å¼€æ–‡ä»¶ï¼š{doc_file_path}\n"
        f"   2. é€‰æ‹©'æ–‡ä»¶' -> 'å¦å­˜ä¸º'\n"
        f"   3. é€‰æ‹©æ ¼å¼ä¸º'Wordæ–‡æ¡£(*.docx)'\n"
        f"   4. ä¿å­˜åé‡æ–°è¿è¡Œè„šæœ¬\n\n"
        f"ğŸ”§ è§£å†³æ–¹æ¡ˆ2ï¼šå®‰è£…LibreOffice (å…è´¹)\n"
        f"   1. è®¿é—®: https://www.libreoffice.org/download/\n"
        f"   2. å®‰è£…åé‡æ–°è¿è¡Œè„šæœ¬ï¼Œå°†è‡ªåŠ¨è½¬æ¢\n\n"
        f"ğŸ”§ è§£å†³æ–¹æ¡ˆ3ï¼šä½¿ç”¨åœ¨çº¿è½¬æ¢å·¥å…·\n"
        f"   - https://convertio.co/doc-docx/\n"
        f"   - https://www.zamzar.com/convert/doc-to-docx/\n\n"
        f"ğŸ’¡ æç¤ºï¼šè½¬æ¢åçš„.docxæ–‡ä»¶å¯ä»¥ç›´æ¥è¢«è„šæœ¬å¤„ç†"
    )


def read_word_document(file_path: str) -> str:
    """
    è¯»å–Wordæ–‡æ¡£å†…å®¹ï¼Œè‡ªåŠ¨å¤„ç†.docå’Œ.docxæ ¼å¼
    
    Args:
        file_path (str): Wordæ–‡æ¡£æ–‡ä»¶è·¯å¾„
        
    Returns:
        str: æ–‡æ¡£çš„çº¯æ–‡æœ¬å†…å®¹
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        Exception: æ–‡æ¡£è¯»å–å¤±è´¥
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    original_path = file_path
    file_extension = file_path.lower().split('.')[-1]
    
    if file_extension not in ['doc', 'docx']:
        raise ValueError("ä»…æ”¯æŒ.docå’Œ.docxæ ¼å¼çš„Wordæ–‡æ¡£")
    
    # å¦‚æœæ˜¯.docæ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸º.docx
    if file_extension == 'doc':
        try:
            file_path = convert_doc_to_docx(file_path)
        except Exception as e:
            logger.error(f"è½¬æ¢.docæ–‡ä»¶å¤±è´¥: {str(e)}")
            raise
    
    try:
        doc = Document(file_path)
        full_text = []
        
        # è¯»å–æ‰€æœ‰æ®µè½
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():  # å¿½ç•¥ç©ºæ®µè½
                full_text.append(paragraph.text)
        
        # è¯»å–è¡¨æ ¼å†…å®¹
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        full_text.append(cell.text)
        
        # å¦‚æœæˆ‘ä»¬è½¬æ¢äº†.docæ–‡ä»¶ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if original_path != file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
            except:
                pass
        
        return '\n'.join(full_text)
        
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡æ¡£å¤±è´¥: {str(e)}")


def split_by_module(content: str, module_keyword: str = "Module") -> List[str]:
    """
    æŒ‰ç…§Moduleå…³é”®è¯åˆ†å‰²æ–‡æ¡£å†…å®¹
    
    Args:
        content (str): æ–‡æ¡£å†…å®¹
        module_keyword (str): åˆ†å‰²å…³é”®è¯ï¼Œé»˜è®¤ä¸º"Module"
        
    Returns:
        List[str]: åˆ†å‰²åçš„å†…å®¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªModuleçš„å†…å®¹
    """
    if not content.strip():
        return []
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾Moduleå…³é”®è¯çš„ä½ç½®
    # åŒ¹é…æ¨¡å¼ï¼šè¡Œé¦–çš„Moduleï¼ˆå¯èƒ½å‰é¢æœ‰æ•°å­—ã€ç©ºæ ¼ç­‰ï¼‰
    pattern = rf'^.*?{re.escape(module_keyword)}\s*\d*.*?$'
    matches = list(re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE))
    
    if not matches:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°Moduleå…³é”®è¯ï¼Œè¿”å›æ•´ä¸ªæ–‡æ¡£ä½œä¸ºä¸€ä¸ªéƒ¨åˆ†
        logger.warning(f"æœªæ‰¾åˆ°'{module_keyword}'å…³é”®è¯ï¼Œè¿”å›å®Œæ•´æ–‡æ¡£")
        return [content]
    
    modules = []
    
    for i, match in enumerate(matches):
        start_pos = match.start()
        
        # ç¡®å®šå½“å‰Moduleçš„ç»“æŸä½ç½®
        if i + 1 < len(matches):
            end_pos = matches[i + 1].start()
        else:
            end_pos = len(content)
        
        # æå–å½“å‰Moduleçš„å†…å®¹
        module_content = content[start_pos:end_pos].strip()
        if module_content:
            modules.append(module_content)
    
    return modules


class TextbookWorkflow:
    """æ•™æè¯¾æ–‡å¤„ç†å·¥ä½œæµ"""
    
    def __init__(self, textbook_path: str, textbook_id: int):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            textbook_path: æ•™ææ–‡æ¡£è·¯å¾„
            textbook_id: æ•™æID
        """
        self.textbook_path = textbook_path
        self.textbook_id = textbook_id
        self.glm4_service = GLM4Service()
        self.temp_dir = None
        self.results_dir = Path("scripts/textbooks_import/results")
        self.results_dir.mkdir(exist_ok=True)
        
    def __enter__(self):
        """è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.temp_dir = tempfile.mkdtemp(prefix="textbook_workflow_")
        logger.info(f"åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•: {self.temp_dir}")
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
            logger.info(f"æ¸…ç†ä¸´æ—¶å·¥ä½œç›®å½•: {self.temp_dir}")
    
    async def process_textbook(self) -> str:
        """
        å¤„ç†æ•™æçš„å®Œæ•´æµç¨‹
        
        Returns:
            str: ç”Ÿæˆçš„SQLæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"å¼€å§‹å¤„ç†æ•™æ: {self.textbook_path}")
        
        # æ­¥éª¤1ï¼šè¯»å–å’Œåˆ†å‰²æ–‡æ¡£
        logger.info("æ­¥éª¤1: è¯»å–å’Œåˆ†å‰²Wordæ–‡æ¡£")
        content = read_word_document(self.textbook_path)
        logger.info(f"æ–‡æ¡£è¯»å–æˆåŠŸï¼Œæ€»å­—ç¬¦æ•°: {len(content)}")
        
        modules = split_by_module(content)
        logger.info(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…±æ‰¾åˆ° {len(modules)} ä¸ªModule")
        
        # æ­¥éª¤2ï¼šæå–è¯¾æ–‡ä¿¡æ¯
        logger.info("æ­¥éª¤2: ä½¿ç”¨GLM-4æå–è¯¾æ–‡ç»“æ„")
        all_lessons = []
        
        for i, module_content in enumerate(modules, 1):
            module_name = f"module_{i:02d}"
            logger.info(f"æ­£åœ¨å¤„ç† {module_name}...")
            
            lessons = await self.extract_lessons_from_module(module_content, module_name)
            if lessons:
                all_lessons.extend(lessons)
                logger.info(f"ä» {module_name} æå–åˆ° {len(lessons)} ä¸ªè¯¾æ–‡")
            else:
                logger.warning(f"{module_name} æœªæå–åˆ°è¯¾æ–‡å†…å®¹")
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶
            await asyncio.sleep(2)
        
        logger.info(f"æ€»è®¡æå–åˆ° {len(all_lessons)} ä¸ªè¯¾æ–‡")
        
        # æ­¥éª¤3ï¼šè®¡ç®—èƒŒè¯µæ—¶é—´å¹¶ç”ŸæˆSQL
        logger.info("æ­¥éª¤3: è®¡ç®—èƒŒè¯µæ—¶é—´å¹¶ç”ŸæˆSQLè¯­å¥")
        sql_file_path = self.generate_final_sql(all_lessons)
        
        logger.info("æ•™æå¤„ç†å®Œæˆï¼")
        return sql_file_path
    
    async def extract_lessons_from_module(self, module_content: str, module_name: str, max_retries: int = 3) -> List[Dict[str, Any]]:
        """
        ä»æ¨¡å—å†…å®¹ä¸­æå–è¯¾æ–‡ä¿¡æ¯ï¼ˆæ”¯æŒé‡è¯•ï¼‰
        
        Args:
            module_content: æ¨¡å—å†…å®¹
            module_name: æ¨¡å—åç§°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡
            
        Returns:
            List[Dict]: æå–çš„è¯¾æ–‡ä¿¡æ¯åˆ—è¡¨
        """
        
        for attempt in range(max_retries + 1):  # æ€»å…±å°è¯• max_retries + 1 æ¬¡
            try:
                if attempt > 0:
                    logger.info(f"æ­£åœ¨é‡è¯•å¤„ç† {module_name}... (ç¬¬{attempt}/{max_retries}æ¬¡é‡è¯•)")
                    # é‡è¯•æ—¶ç¨å¾®å¢åŠ å»¶è¿Ÿ
                    await asyncio.sleep(3)
                
                prompt = self.get_extraction_prompt(module_content)
                request = GLM4Request(prompt=prompt, temperature=0.3)
                
                response = await self.glm4_service.basic_call(request)
                
                # æå–å“åº”å†…å®¹
                if response.choices and len(response.choices) > 0:
                    message = response.choices[0].message
                    content = message.get('content', '') if isinstance(message, dict) else str(message)
                    
                    # è§£æJSON
                    try:
                        result = json.loads(content)
                        lessons = result.get('lessons', [])
                        if lessons:  # åªæœ‰æˆåŠŸæå–åˆ°è¯¾æ–‡æ‰ç®—æˆåŠŸ
                            if attempt > 0:
                                logger.info(f"âœ“ {module_name} é‡è¯•æˆåŠŸï¼Œæå–åˆ°{len(lessons)}ä¸ªè¯¾æ–‡")
                            return lessons
                        else:
                            logger.warning(f"GLM-4è¿”å›ç©ºè¯¾æ–‡åˆ—è¡¨: {module_name}")
                            if attempt < max_retries:
                                continue  # ç»§ç»­é‡è¯•
                            else:
                                return []
                                
                    except json.JSONDecodeError as e:
                        logger.error(f"JSONè§£æå¤±è´¥ {module_name} (å°è¯•{attempt + 1}/{max_retries + 1}): {str(e)}")
                        logger.error(f"å“åº”å†…å®¹: {content}")
                        if attempt < max_retries:
                            continue  # ç»§ç»­é‡è¯•
                        else:
                            return []
                else:
                    logger.error(f"GLM-4å“åº”ä¸ºç©º: {module_name} (å°è¯•{attempt + 1}/{max_retries + 1})")
                    if attempt < max_retries:
                        continue  # ç»§ç»­é‡è¯•
                    else:
                        return []
                        
            except Exception as e:
                logger.error(f"æå–è¯¾æ–‡ä¿¡æ¯å¤±è´¥ {module_name} (å°è¯•{attempt + 1}/{max_retries + 1}): {str(e)}")
                if attempt < max_retries:
                    continue  # ç»§ç»­é‡è¯•
                else:
                    return []
        
        return []
    
    def get_extraction_prompt(self, module_content: str) -> str:
        """
        æ„å»ºGLM-4æå–æç¤ºè¯
        
        Args:
            module_content: æ¨¡å—å†…å®¹
            
        Returns:
            str: GLM-4æç¤ºè¯
        """
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹è‹±è¯­æ•™æè¯¾æ–‡æ¨¡å—å†…å®¹ï¼Œæå–å¹¶æ ¡æ­£å…¶ç»“æ„åŒ–ä¿¡æ¯ã€‚

åŸå§‹å†…å®¹ï¼š
{module_content}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºæ¯ä¸ªè¯¾æ–‡å•å…ƒçš„ä¿¡æ¯ï¼Œæ³¨æ„æ ¡æ­£è‹±æ–‡å’Œç¿»è¯‘ä¸­çš„é”™è¯¯ï¼š

{{
  "lessons": [
    {{
      "unit_number": "Module X Unit Y",
      "unit_title": "å•å…ƒè‹±æ–‡æ ‡é¢˜",
      "lesson_title": "è¯¾æ–‡ç±»å‹æ ‡é¢˜ï¼ˆå¦‚ï¼š1. Listen and chantï¼‰",
      "title": "è¯¾æ–‡æ ‡é¢˜ï¼ˆå¦‚ï¼šListen and chantï¼‰",
      "content": "è‹±æ–‡è¯¾æ–‡å†…å®¹ï¼ˆæ ¡æ­£åçš„ï¼ŒæŒ‰è¯­ä¹‰åˆ†æ®µï¼‰",
      "translation": "ä¸­æ–‡ç¿»è¯‘ï¼ˆæ ¡æ­£åçš„ï¼ŒæŒ‰è¯­ä¹‰åˆ†æ®µï¼‰",
      "difficulty_level": 2
    }}
  ]
}}

æå–è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«æ¯ä¸ªUnitå’Œlessonçš„è¾¹ç•Œ
2. æ ¡æ­£è‹±æ–‡è¯­æ³•ã€æ‹¼å†™é”™è¯¯
3. æ ¡æ­£ä¸­æ–‡ç¿»è¯‘é”™è¯¯ï¼Œç¡®ä¿é€šé¡ºå‡†ç¡®
4. contentå­—æ®µåªåŒ…å«è‹±æ–‡åŸæ–‡ï¼Œtranslationå­—æ®µåªåŒ…å«ä¸­æ–‡ç¿»è¯‘
5. **è¯­ä¹‰åˆ†æ®µè¦æ±‚**ï¼š
   - å¯¹äºcontentå’Œtranslationå­—æ®µï¼Œè¯·æŒ‰ç…§è¯­ä¹‰è¿›è¡Œåˆç†åˆ†æ®µ
   - ä½¿ç”¨æ¢è¡Œç¬¦ï¼ˆ\\nï¼‰åˆ†éš”ä¸åŒçš„è¯­ä¹‰æ®µè½
   - åˆ†æ®µåŸåˆ™ï¼š
     * å¯¹è¯å†…å®¹ï¼šæ¯ä¸ªè¯´è¯è€…çš„è¯ä¸ºä¸€æ®µ
     * æ•…äº‹/å™è¿°ï¼šæŒ‰ç…§æ„æ€ç›¸å…³çš„å¥ç¾¤åˆ†æ®µ
     * æ­Œè°£/è¯—æ­Œï¼šæŒ‰ç…§éŸµå¾‹æˆ–æ„æ€åˆ†è¡Œ
     * æè¿°æ€§æ–‡å­—ï¼šæŒ‰ç…§ä¸»é¢˜æˆ–åœºæ™¯åˆ†æ®µ
   - ç¡®ä¿åˆ†æ®µåçš„å†…å®¹é€»è¾‘æ¸…æ™°ï¼Œä¾¿äºé˜…è¯»å’ŒèƒŒè¯µ
6. difficulty_levelè¯„ä¼°è¯¾æ–‡éš¾åº¦ï¼š1-ç®€å•ï¼ˆå•è¯ç®€å•ã€å¥å¼ç®€å•ï¼‰ï¼Œ2-ä¸­ç­‰ï¼ˆé€‚ä¸­éš¾åº¦ï¼‰ï¼Œ3-å›°éš¾ï¼ˆè¯æ±‡å¤æ‚ã€è¯­æ³•å¤æ‚ï¼‰
7. ä¿æŒè¯¾æ–‡çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
8. ç¡®ä¿è¾“å‡ºçš„æ˜¯æ ‡å‡†çš„JSONæ ¼å¼

åˆ†æ®µç¤ºä¾‹ï¼š
- å¯¹è¯å½¢å¼ï¼š"Hello, Amy.\\nHello, Sam.\\nHow are you?\\nI'm fine, thank you."
- å™è¿°å½¢å¼ï¼š"This is my family.\\nMy father is a doctor.\\nMy mother is a teacher.\\nI love my family."
- æ­Œè°£å½¢å¼ï¼š"Ten little fingers,\\nTen little toes,\\nTwo little ears,\\nAnd one little nose."

è¯·ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—ã€‚
"""
        return prompt
    
    def generate_final_sql(self, lessons: List[Dict[str, Any]]) -> str:
        """
        ç”ŸæˆåŒ…å«recommend_minuteså­—æ®µçš„æœ€ç»ˆSQLè¯­å¥
        
        Args:
            lessons: è¯¾æ–‡ä¿¡æ¯åˆ—è¡¨
            
        Returns:
            str: SQLæ–‡ä»¶è·¯å¾„
        """
        if not lessons:
            logger.warning("æ²¡æœ‰è¯¾æ–‡æ•°æ®ï¼Œæ— æ³•ç”ŸæˆSQL")
            return ""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        sql_file = self.results_dir / f"textbooks_lessons_insert_{timestamp}.sql"
        
        # ç”ŸæˆSQLå†…å®¹
        sql_parts = []
        sql_parts.append("-- æ•™æè¯¾æ–‡æ•°æ®æ’å…¥è¯­å¥")
        sql_parts.append(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        sql_parts.append(f"-- æ•™æID: {self.textbook_id}")
        sql_parts.append(f"-- æ€»è¯¾æ–‡æ•°: {len(lessons)}")
        sql_parts.append("")
        sql_parts.append("INSERT INTO public.textbooks_lessons (")
        sql_parts.append("  textbook_id, unit_number, unit_title, lesson_title,")
        sql_parts.append("  lesson_order, title, content, translation,")
        sql_parts.append("  recommend_minutes, author, source, created_at, updated_at")
        sql_parts.append(") VALUES")
        
        value_parts = []
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # lesson_order ä»1å¼€å§‹é€’å¢ï¼Œè¡¨ç¤ºè¯¾æ–‡åœ¨æ•´æœ¬æ•™æä¸­çš„åºå·
        for lesson_order, lesson in enumerate(lessons, 1):
            # è®¡ç®—èƒŒè¯µæ—¶é—´
            content = lesson.get('content', '')
            word_count = count_words(content)
            difficulty_level = lesson.get('difficulty_level', 2)  # ä½¿ç”¨æ¨¡å‹è¾“å‡ºçš„éš¾åº¦ç­‰çº§ï¼Œé»˜è®¤ä¸º2
            recommend_minutes = estimate_memorization_time_simple(word_count, difficulty_level=difficulty_level)
            
            # å¤„ç†å­—ç¬¦ä¸²ä¸­çš„å•å¼•å·ï¼Œé˜²æ­¢SQLæ³¨å…¥
            def escape_sql_string(s: str) -> str:
                if s is None:
                    return 'NULL'
                return "'" + str(s).replace("'", "''") + "'"
            
            value_part = f"""(
  {self.textbook_id},
  {escape_sql_string(lesson.get('unit_number', ''))},
  {escape_sql_string(lesson.get('unit_title', ''))},
  {escape_sql_string(lesson.get('lesson_title', ''))},
  {lesson_order},
  {escape_sql_string(lesson.get('title', ''))},
  {escape_sql_string(content)},
  {escape_sql_string(lesson.get('translation', ''))},
  {recommend_minutes},
  'å¤–ç ”ç¤¾',
  'æ•™æå¯¼å…¥',
  '{current_time}',
  '{current_time}'
)"""
            value_parts.append(value_part)
        
        sql_parts.append(",\n".join(value_parts))
        sql_parts.append(";")
        
        # ä¿å­˜SQLæ–‡ä»¶
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(sql_parts))
        
        logger.info(f"SQLè¯­å¥å·²ä¿å­˜: {sql_file}")
        
        # ç”Ÿæˆå¤„ç†æ‘˜è¦
        summary = []
        summary.append(f"å¤„ç†å®Œæˆæ‘˜è¦:")
        summary.append(f"- æ•™æè·¯å¾„: {self.textbook_path}")
        summary.append(f"- æ•™æID: {self.textbook_id}")
        summary.append(f"- æ€»è¯¾æ–‡æ•°: {len(lessons)}")
        summary.append(f"- SQLæ–‡ä»¶: {sql_file}")
        summary.append("")
        summary.append("è¯¾æ–‡è¯¦æƒ…:")
        
        for i, lesson in enumerate(lessons, 1):
            content = lesson.get('content', '')
            word_count = count_words(content)
            difficulty_level = lesson.get('difficulty_level', 2)  # ä½¿ç”¨æ¨¡å‹è¾“å‡ºçš„éš¾åº¦ç­‰çº§ï¼Œé»˜è®¤ä¸º2
            recommend_minutes = estimate_memorization_time_simple(word_count, difficulty_level=difficulty_level)
            
            difficulty_text = {1: 'ç®€å•', 2: 'ä¸­ç­‰', 3: 'å›°éš¾'}.get(difficulty_level, 'ä¸­ç­‰')
            summary.append(f"  {i}. {lesson.get('title', 'N/A')} "
                         f"({word_count}è¯, éš¾åº¦:{difficulty_text}, {recommend_minutes}åˆ†é’Ÿ)")
        
        summary_text = "\n".join(summary)
        logger.info(f"\n{summary_text}")
        
        # ä¿å­˜å¤„ç†æ‘˜è¦
        summary_file = self.results_dir / f"processing_summary_{timestamp}.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_text)
        
        return str(sql_file)


async def main(file_path: str, textbook_id: int):
    """ä¸»ç¨‹åº"""
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(file_path):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    
    try:
        with TextbookWorkflow(file_path, textbook_id) as workflow:
            sql_file_path = await workflow.process_textbook()
            
            print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“„ è¾“å…¥æ–‡ä»¶: {file_path}")
            print(f"ğŸ†” æ•™æID: {textbook_id}")
            print(f"ğŸ“ ç”Ÿæˆçš„SQLæ–‡ä»¶: {sql_file_path}")
            print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥ï¼šå°†SQLæ–‡ä»¶å¯¼å…¥åˆ°æ•°æ®åº“ä¸­")
            
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    filepath = "/Users/ethan/PycharmProjects/polly-memo-fastapi/scripts/textbooks_import/5ä¸‹ å¤–ç ”ä¸€èµ· è¯¾æ–‡.doc"
    textbook_id = 2
    asyncio.run(main(filepath, textbook_id)) 